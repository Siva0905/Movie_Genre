{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vignesh S\\AppData\\Local\\Temp\\ipykernel_8796\\1754144864.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_path, sep=':::', header=None, names=[ 'Title', 'Genre', 'Plot'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Title  Genre   Plot\n",
      "1      False  False  False\n",
      "2      False  False  False\n",
      "3      False  False  False\n",
      "4      False  False  False\n",
      "5      False  False  False\n",
      "...      ...    ...    ...\n",
      "54210  False  False  False\n",
      "54211  False  False  False\n",
      "54212  False  False  False\n",
      "54213  False  False  False\n",
      "54214  False  False  False\n",
      "\n",
      "[54214 rows x 3 columns]\n",
      "Missing values:\n",
      " Title    0\n",
      "Genre    0\n",
      "Plot     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from a text document file\n",
    "file_path = \"D:\\\\CodSoft\\\\MovieGenre\\\\train_data.txt\"\n",
    "# Assuming each line in the text document represents a movie entry with columns separated by ':::'\n",
    "# Adjust the separator based on the actual format of your dataset\n",
    "df = pd.read_csv(file_path, sep=':::', header=None, names=[ 'Title', 'Genre', 'Plot'])\n",
    "\n",
    "# Data Cleaning\n",
    "# Check for missing values\n",
    "mm=df.isnull()\n",
    "print(mm)\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Example: Replace missing values in 'Plot' column with an empty string\n",
    "#df['Plot'].fillna('', inplace=True)\n",
    "\n",
    "# # Feature Engineering\n",
    "# # Tokenize and vectorize the plot summaries\n",
    "# # Example: Use CountVectorizer to tokenize and convert plot summaries into numerical representations\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# X_plot = vectorizer.fit_transform(df['Plot'])\n",
    "\n",
    "# # Convert genre labels into numerical representations using label encoding\n",
    "# # Label encoder is used to transform categorical labels into numerical labels\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_genre = label_encoder.fit_transform(df['Genre'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\n",
    "# Feature Engineering\n",
    "# Tokenize and vectorize the plot summaries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Tokenize and convert plot summaries into numerical representations\n",
    "X_plot = vectorizer.fit_transform(df['Plot'])\n",
    "\n",
    "# Now, X_plot contains the vectorized plot summaries.\n",
    "# Each row represents a movie, and each column represents a unique word from the plot summaries.\n",
    "# The cell value represents the frequency of the word in the corresponding movie's plot summary.\n",
    "\n",
    "# Convert genre labels into numerical representations using label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_genre = label_encoder.fit_transform(df['Genre'])\n",
    "\n",
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_plot, y_genre, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, X_train, X_test contain the vectorized plot summaries, and y_train, y_test contain the genre labels.\n",
    "\n",
    "# Data is now preprocessed and ready for model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best Parameters: {'classifier__decision_tree__max_depth': 10, 'classifier__naive_bayes__alpha': 0.1, 'classifier__weights': (1, 1)}\n",
      "Best Cross-Validation Accuracy: 0.5548869059970948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define a pipeline for model training (without preprocessing)\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', VotingClassifier(estimators=[\n",
    "        ('naive_bayes', MultinomialNB()),\n",
    "        ('decision_tree', DecisionTreeClassifier())\n",
    "    ], voting='soft'))  # Soft voting for probabilistic predictions\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune (reduced ranges)\n",
    "parameters = {\n",
    "    'classifier__naive_bayes__alpha': [0.1, 0.5],  # Alpha parameter for Multinomial Naive Bayes\n",
    "    'classifier__decision_tree__max_depth': [None, 10],  # Max depth for Decision Tree\n",
    "    'classifier__weights': [(1, 1)]  # Voting weights for the classifiers\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation with reduced folds (e.g., cv=3)\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)    #Model Trained in the name of grid_search.fit\n",
    "\n",
    "# Display the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5603615235635894\n",
      "Precision: 0.534200042093326\n",
      "Recall: 0.5603615235635894\n",
      "F1 Score: 0.5414306823107056\n",
      "Confusion Matrix:\n",
      " [[ 100    1    6    1    1   13    3   20   55    0    0    0    0   10\n",
      "     0    0    0    0    1    3    9    5    9    0   25    0    1]\n",
      " [   1   43   11    0    0   24    0    3   17    0    0    0    0    4\n",
      "     1    0    0    0    1    0    0    5    0    0    1    0    1]\n",
      " [   8    9   26    1    0    9    1   21   16    1    0    0    0   12\n",
      "     0    0    0    0    2    0    7    8    1    0    7    1    9]\n",
      " [   5    0    5   13    0   12    0   13   11   13    2    0    0    4\n",
      "     2    0    0    0    0    1    9   10    0    1    3    0    0]\n",
      " [   0    0    0    0    0    2    0   35   11    0    1    0    1    0\n",
      "     2    0    0    0    0    0    0    7    1    0    0    1    0]\n",
      " [  15    2    7    4    0  784    3   77  322   14    3    0    0   22\n",
      "    22    8    0    3   22   19    5   62    3   12   25    2    7]\n",
      " [  13    0    0    0    0   15    3    7   26    0    0    0    0    8\n",
      "     0    0    1    0    2    2    1    4    0    0   20    0    5]\n",
      " [   7    1    6    1    4   37    1 2117  147    8    0    1    5    8\n",
      "    74    2    0    2   44    0    8  149   21   10    4    1    1]\n",
      " [  47    4   10    1    3  247    8  277 1726    5    7    0    2   37\n",
      "     2    7    3    4    3   46    2  153    1   10   61    5   26]\n",
      " [   5    0    1    6    0   26    0   20   27   30    0    0    0    4\n",
      "     6    0    0    0    8    0    0   10    1    3    2    0    1]\n",
      " [   5    1    4    3    0    6    0    8   19    0    2    0    1   11\n",
      "     0    0    0    0    0    0    1   11    0    0    1    1    0]\n",
      " [   0    0    0    0    0    3    0    5    0    1    0   19    0    0\n",
      "     1    1    0    0    5    0    0    2    1    2    0    0    0]\n",
      " [   2    0    1    1    0    0    0   29    5    0    1    0    2    0\n",
      "     0    0    0    0    1    1    0    1    0    0    1    0    0]\n",
      " [   7    0    0    1    0   19    1   17   40    0    0    0    0  299\n",
      "     4    0    0    0    2    1    4   12    0    0   22    0    2]\n",
      " [   0    0    0    0    0    6    0   25    2    0    1    0    0    0\n",
      "   101    4    0    0    2    0    0    2    0    1    0    0    0]\n",
      " [   0    0    0    0    0   12    0    7   14    1    1    0    0    1\n",
      "     8    1    1    0    0    2    0    2    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0    3   14    0    0    0    0   10\n",
      "     1    0    2    0    0    1    0    4    0    0   15    0    2]\n",
      " [   0    0    0    0    0    0    0   17    0    0    0    0    0    0\n",
      "     3    0    0    0    6    0    0    2    0    5    1    0    0]\n",
      " [   0    1    1    0    0   22    0   53    9    2    0    1    0    1\n",
      "     5    0    0    0   90    0    1    3    1    2    0    0    0]\n",
      " [   4    0    0    0    0   24    1    5   79    1    0    0    0    2\n",
      "     1    0    0    0    2   22    0    8    0    0    2    0    0]\n",
      " [   6    0    3    0    0   11    0   24   10    1    0    0    0   18\n",
      "     1    0    0    0    2    1   42   14    0    1    9    0    0]\n",
      " [   8    0    5    2    1  109    0  272  222    7    1    0    0   16\n",
      "     8    0    0    0    9    3    4  347    1    4   24    0    2]\n",
      " [   1    0    0    0    0    3    0   28    0    0    0    0    0    0\n",
      "     1    0    0    0    7    0    0    3   48    2    0    0    0]\n",
      " [   0    0    0    0    0    2    0   29    1    1    0    1    0    0\n",
      "     7    0    0    0   18    0    0    5    0   17    0    0    0]\n",
      " [  16    0    1    0    0   23    3   15  112    1    0    0    0   52\n",
      "     0    0    1    0    0    0    2   10    0    0   72    1    0]\n",
      " [   6    0    0    0    0    0    0    7    5    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    1    0]\n",
      " [   4    0    0    0    0    6    0    3   16    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0    0    1    0  169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming you have already trained your model(s) and obtained predictions on the test set\n",
    "\n",
    "# Evaluate the model(s) on the test set\n",
    "y_pred = grid_search.predict(X_test)  # Replace 'grid_search' with your trained model object\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
